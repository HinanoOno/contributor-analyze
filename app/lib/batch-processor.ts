/**
 * ãƒãƒƒãƒå‡¦ç†ã¨ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ã®å…±é€šãƒ©ã‚¤ãƒ–ãƒ©ãƒª
 */

export interface BatchProcessorOptions {
  batchSize?: number;
  batchDelayMs?: number;
  itemTimeoutMs?: number;
  batchTimeoutMs?: number;
  maxRetries?: number;
  baseRetryDelay?: number;
  concurrentBatches?: number;
}

export interface ProcessorResult<T> {
  success: boolean;
  data?: T;
  error?: string;
}

// ãƒ¬ãƒ¼ãƒˆåˆ¶é™/ãƒªãƒˆãƒ©ã‚¤ç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå…±é€šåŒ–ï¼‰
let last429CooldownUntil = 0;

function parseRetryDelayMs(msg: string | undefined): number | null {
  if (!msg) return null;
  const match = msg.match(/retryDelay"?:"?(\d+)(s|sec)/i);
  if (match) {
    const sec = parseInt(match[1], 10);
    if (!isNaN(sec)) return sec * 1000;
  }
  return null;
}

async function ensureCooldown() {
  const now = Date.now();
  if (now < last429CooldownUntil) {
    const wait = last429CooldownUntil - now;
    console.log(`â³ Global cooldown active: waiting ${wait}ms`);
    await new Promise((r) => setTimeout(r, wait));
  }
}

export async function retryWithBackoff<T>(
  operation: () => Promise<T>,
  maxRetries: number = 4,
  baseDelay: number = 1200,
): Promise<T> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      await ensureCooldown();
      return await operation();
    } catch (e: any) {
      const msg = e?.message || '';
      const status = e?.status || (typeof msg === 'string' && msg.match(/\[(\d{3}) /)?.[1]);
      const isRate = status == 429 || msg.includes('[429');
      const isServer = [500, 503].includes(Number(status));
      const isLast = i === maxRetries - 1;

      if (isRate) {
        const delay = (parseRetryDelayMs(msg) || 30_000) + Math.floor(Math.random() * 1500);
        last429CooldownUntil = Date.now() + delay;
        if (isLast) throw e;
        console.warn(`ğŸš¦ Rate limit (attempt ${i + 1}/${maxRetries}) wait ${delay}ms`);
        await new Promise((r) => setTimeout(r, delay));
        continue;
      }

      if (!isServer || isLast) throw e;
      const delay = baseDelay * Math.pow(2, i) + Math.floor(Math.random() * 400);
      console.log(`âš ï¸ Error (attempt ${i + 1}/${maxRetries}) retry in ${delay}ms`);
      await new Promise((r) => setTimeout(r, delay));
    }
  }
  throw new Error('Max retries exceeded');
}

/**
 * ãƒãƒƒãƒå‡¦ç†ã‚¯ãƒ©ã‚¹
 */
export class BatchProcessor<TInput, TOutput> {
  private options: Required<BatchProcessorOptions>;

  constructor(options: BatchProcessorOptions = {}) {
    this.options = {
      batchSize: options.batchSize ?? 2,
      batchDelayMs: options.batchDelayMs ?? 3000,
      itemTimeoutMs: options.itemTimeoutMs ?? 3 * 60 * 1000, // 3åˆ†
      batchTimeoutMs: options.batchTimeoutMs ?? 5 * 60 * 1000, // 5åˆ†
      maxRetries: options.maxRetries ?? 4,
      baseRetryDelay: options.baseRetryDelay ?? 1200,
      concurrentBatches: options.concurrentBatches ?? 1,
    };
  }

  /**
   * å˜ä¸€ã‚¢ã‚¤ãƒ†ãƒ ã‚’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§å‡¦ç†
   */
  private async processItemWithTimeout(
    item: TInput,
    processor: (item: TInput) => Promise<TOutput | null>,
    itemName: string,
  ): Promise<TOutput | null> {
    const timeoutPromise = new Promise<never>((_, reject) =>
      setTimeout(() => reject(new Error(`${itemName} processing timeout`)), this.options.itemTimeoutMs),
    );

    const processPromise = async (): Promise<TOutput | null> => {
      try {
        return await retryWithBackoff(() => processor(item), this.options.maxRetries, this.options.baseRetryDelay);
      } catch (error) {
        console.error(`âŒ Error processing ${itemName}:`, error);
        return null;
      }
    };

    try {
      return await Promise.race([processPromise(), timeoutPromise]);
    } catch (error) {
      console.error(`âŒ ${itemName} processing failed or timed out:`, error);
      return null;
    }
  }

  /**
   * ãƒãƒƒãƒå‡¦ç†ãƒ¡ã‚¤ãƒ³é–¢æ•°
   */
  async processBatches(
    items: TInput[],
    processor: (item: TInput) => Promise<TOutput | null>,
    getItemName: (item: TInput) => string,
    processName: string = 'items',
  ): Promise<TOutput[]> {
    console.log(`ğŸš€ Starting batch processing for ${items.length} ${processName}...`);

    if (this.options.concurrentBatches > 1) {
      return this.processConcurrentBatches(items, processor, getItemName, processName);
    }

    const allResults: TOutput[] = [];
    const totalBatches = Math.ceil(items.length / this.options.batchSize);

    for (let i = 0; i < items.length; i += this.options.batchSize) {
      const batch = items.slice(i, i + this.options.batchSize);
      const batchNumber = Math.floor(i / this.options.batchSize) + 1;

      const batchItemNames = batch.map(getItemName);
      console.log(`ğŸ”„ Processing batch ${batchNumber}/${totalBatches}: ${batchItemNames.join(', ')}`);

      try {
        // ãƒãƒƒãƒã”ã¨ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
        const batchPromise = Promise.allSettled(
          batch.map((item) => this.processItemWithTimeout(item, processor, getItemName(item))),
        );

        const timeoutPromise = new Promise<never>((_, reject) =>
          setTimeout(() => reject(new Error(`Batch ${batchNumber} timeout`)), this.options.batchTimeoutMs),
        );

        const batchResults = (await Promise.race([
          batchPromise,
          timeoutPromise,
        ])) as PromiseSettledResult<TOutput | null>[];

        // æˆåŠŸã—ãŸçµæœã®ã¿ã‚’æŠ½å‡º
        const successfulResults = batchResults
          .filter(
            (result): result is PromiseFulfilledResult<TOutput> =>
              result.status === 'fulfilled' && result.value !== null,
          )
          .map((result) => result.value);

        allResults.push(...successfulResults);

        const successCount = successfulResults.length;
        console.log(`âœ… Batch ${batchNumber}/${totalBatches} completed (${successCount}/${batch.length} successful)`);

        // é€²æ—å ±å‘Š
        console.log(`ğŸ“Š Overall progress: ${allResults.length}/${items.length} ${processName} processed successfully`);
      } catch (error) {
        console.error(`âŒ Batch ${batchNumber} failed:`, error);
        // ãƒãƒƒãƒãŒå¤±æ•—ã—ã¦ã‚‚å‡¦ç†ã‚’ç¶™ç¶š
      }

      // ãƒãƒƒãƒé–“ã®å¾…æ©Ÿï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰
      if (i + this.options.batchSize < items.length) {
        console.log(`â±ï¸ Waiting ${this.options.batchDelayMs}ms between batches...`);
        await new Promise((resolve) => setTimeout(resolve, this.options.batchDelayMs));
      }
    }

    console.log(
      `âœ… Batch processing completed: ${allResults.length}/${items.length} ${processName} processed successfully`,
    );
    return allResults;
  }

  /**
   * è¤‡æ•°ãƒãƒƒãƒã‚’ä¸¦è¡Œå®Ÿè¡Œã™ã‚‹å‡¦ç†
   */
  private async processConcurrentBatches(
    items: TInput[],
    processor: (item: TInput) => Promise<TOutput | null>,
    getItemName: (item: TInput) => string,
    processName: string,
  ): Promise<TOutput[]> {
    const allResults: TOutput[] = [];

    // å…¨ãƒãƒƒãƒã‚’ä½œæˆ
    const batches = [];
    for (let i = 0; i < items.length; i += this.options.batchSize) {
      batches.push(items.slice(i, i + this.options.batchSize));
    }

    console.log(`Processing ${batches.length} batches with ${this.options.concurrentBatches} concurrent batches...`);

    // è¤‡æ•°ãƒãƒƒãƒã‚’ä¸¦è¡Œå®Ÿè¡Œ
    for (let i = 0; i < batches.length; i += this.options.concurrentBatches) {
      const concurrentBatches = batches.slice(i, i + this.options.concurrentBatches);

      const batchPromises = concurrentBatches.map(async (batchItems, batchIndex) => {
        const actualBatchNumber = i + batchIndex + 1;
        console.log(
          `Processing concurrent batch ${actualBatchNumber}/${batches.length} with ${batchItems.length} items...`,
        );

        try {
          const batchPromise = Promise.allSettled(
            batchItems.map((item) => this.processItemWithTimeout(item, processor, getItemName(item))),
          );

          const timeoutPromise = new Promise<never>((_, reject) =>
            setTimeout(() => reject(new Error(`Batch ${actualBatchNumber} timeout`)), this.options.batchTimeoutMs),
          );

          const batchResults = (await Promise.race([
            batchPromise,
            timeoutPromise,
          ])) as PromiseSettledResult<TOutput | null>[];

          // æˆåŠŸã—ãŸçµæœã®ã¿ã‚’æŠ½å‡º
          const successfulResults = batchResults
            .filter(
              (result): result is PromiseFulfilledResult<TOutput> =>
                result.status === 'fulfilled' && result.value !== null,
            )
            .map((result) => result.value);

          console.log(
            `âœ… Concurrent batch ${actualBatchNumber}/${batches.length} completed (${successfulResults.length}/${batchItems.length} successful)`,
          );
          return successfulResults;
        } catch (batchError) {
          console.error(`âŒ Concurrent batch ${actualBatchNumber} processing failed:`, batchError);
          return [];
        }
      });

      try {
        // è¤‡æ•°ãƒãƒƒãƒã‚’ä¸¦åˆ—å®Ÿè¡Œ
        const concurrentResults = await Promise.all(batchPromises);
        // çµæœã‚’ãƒ•ãƒ©ãƒƒãƒˆã«å±•é–‹
        allResults.push(...concurrentResults.flat());
      } catch (concurrentError) {
        console.error(`âŒ Concurrent batch processing failed:`, concurrentError);
      }

      // ãƒãƒƒãƒé–“ã®å¾…æ©Ÿï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰
      if (i + this.options.concurrentBatches < batches.length) {
        console.log(`â±ï¸ Waiting ${this.options.batchDelayMs}ms between concurrent batch groups...`);
        await new Promise((resolve) => setTimeout(resolve, this.options.batchDelayMs));
      }
    }

    console.log(
      `âœ… Concurrent batch processing completed: ${allResults.length}/${items.length} ${processName} processed successfully`,
    );
    return allResults;
  }
}
